i1 <- (ind)[i]
i0 <- setdiff(ind, i1)
if (length(i0) == 0)
return(Q)
Q0 <- as(Q[i0, i0, drop = FALSE], "symmetricMatrix")
L0 <- Cholesky(Q0, ...)
ans <- Q[i1, i1, drop = FALSE] - Q[i1, i0, drop = FALSE] %*%
solve(Q0, as.matrix(Q[i0, i1, drop = FALSE]))
ans
}
# n.b. won't work for terms with more than 2 args ...
# @examples
# replaceForm(quote(a(b+x*c(y,z))),quote(y),quote(R))
# ss <- ~(1 | cask:batch) + (1 | batch)
# replaceForm(ss,quote(cask:batch),quote(batch:cask))
replaceForm <- function(term,target,repl) {
if (identical(term,target)) return(repl)
if (!inForm(term,target)) return(term)
if (length(term) == 2) {
return(substitute(OP(x),list(OP=term[[1]],x=replaceForm(term[[2]],target,repl))))
}
return(substitute(OP(x,y),list(OP=term[[1]],
x=replaceForm(term[[2]],target,repl),
y=replaceForm(term[[3]],target,repl))))
}
parallel_default <- function(parallel=c("no","multicore","snow"),ncpus=1) {
##  boilerplate parallel-handling stuff, copied from lme4
if (missing(parallel)) parallel <- getOption("profile.parallel", "no")
parallel <- match.arg(parallel)
do_parallel <- (parallel != "no" && ncpus > 1L)
if (do_parallel && parallel == "multicore" &&
.Platform$OS.type == "windows") {
warning("no multicore on Windows, falling back to non-parallel")
parallel <- "no"
}
return(list(parallel=parallel,do_parallel=do_parallel))
}
##' translate vector of correlation parameters to correlation values,
##' following the definition at \url{http://kaskr.github.io/adcomp/classUNSTRUCTURED__CORR__t.html}:
##' if \eqn{L} is the lower-triangular matrix with 1 on the diagonal and the correlation parameters in the lower triangle, then the correlation matrix is defined as \eqn{\Sigma = D^{-1/2} L L^\top D^{-1/2}}{Sigma = sqrt(D) L L' sqrt(D)}, where \eqn{D = \textrm{diag}(L L^\top)}{D = diag(L L')}. For a single correlation parameter \eqn{\theta_0}{theta0}, this works out to \eqn{\rho = \theta_0/\sqrt{1+\theta_0^2}}{rho = theta0/sqrt(1+theta0^2)}.
##' @param theta vector of internal correlation parameters
##' @return a vector of correlation values
##' @examples
##' th0 <- 0.5
##' stopifnot(all.equal(get_cor(th0),th0/sqrt(1+th0^2)))
##' get_cor(c(0.5,0.2,0.5))
##' @export
get_cor <- function(theta) {
n <- round((1  + sqrt(1+8*length(theta)))/2) ## dim of cor matrix
L <- diag(n)
L[lower.tri(L)] <- theta
cL <- tcrossprod(L)
Dh <- diag(1/sqrt(diag(cL)))
cc <- Dh %*% cL %*% Dh
return(cc[lower.tri(cc)])
}
match_which <- function(x,y) {
which(sapply(y,function(z) x %in% z))
}
## reassign predvars to have term vars in the right order,
##  but with 'predvars' values inserted where appropriate
fix_predvars <- function(pv,tt) {
if (length(tt)==3) {
## convert two-sided to one-sided formula
tt <- RHSForm(tt, as.form=TRUE)
}
## ugh, deparsing again ...
tt_vars <- vapply(attr(tt,"variables"),deparse,character(1))[-1]
## remove terminal paren - e.g. match term poly(x, 2) to
##   predvar poly(x, 2, <stuff>)
## beginning of string, including open-paren, colon
##  and *first* comma but not arg ...
init_regexp <- "^([(:_.[:alnum:]]+).*"
tt_vars_short <- gsub(init_regexp,"\\1",tt_vars)
if (is.null(pv) || length(tt_vars)==0) return(NULL)
new_pv <- quote(list())
## maybe multiple variables per pv term ... [[-1]] ignores head
## FIXME: test for really long predvar strings ????
pv_strings <- vapply(pv,deparse,FUN.VALUE=character(1),
width.cutoff=500)[-1]
pv_strings <- gsub(init_regexp,"\\1",pv_strings)
for (i in seq_along(tt_vars)) {
w <- match(tt_vars_short[[i]],pv_strings)
if (!is.na(w)) {
new_pv[[i+1]] <- pv[[w+1]]
} else {
## insert symbol from term vars
new_pv[[i+1]] <- as.symbol(tt_vars[[i]])
}
}
return(new_pv)
}
hasRandom <- function(x) {
pl <- getParList(x)
return(length(unlist(pl[grep("^theta",names(pl))]))>0)
}
getParms <- function(parm=NULL, object, full=FALSE) {
vv <- vcov(object, full=TRUE)
sds <- sqrt(diag(vv))
pnames <- names(sds) <- rownames(vv)
intnames <- names(object$obj$env$last.par) ## internal names
## "beta" vals may be identified by object$obj$env$random, if REML
intnames <- intnames[intnames != "b"]
if (length(pnames) != length(sds)) { ## shouldn't happen ...
stop("length mismatch between internal and external parameter names")
}
if (is.null(parm)) {
if (!full && trivialDisp(object)) {
parm <- grep("betad", intnames, invert=TRUE)
} else {
parm <- seq_along(sds)
}
}
if (is.character(parm)) {
if (identical(parm,"theta_")) {
parm <- which(intnames=="theta")
} else if (identical(parm,"beta_")) {
if (trivialDisp(object)) {
## include conditional and zi params
##   but not dispersion params
parm <- grep("^beta(zi)?$",intnames)
} else {
parm <- grep("beta",intnames)
}
} else if (identical(parm, "disp_") ||
identical(parm, "sigma")) {
parm <- grep("^betad", intnames)
} else { ## generic parameter vector
nparm <- match(parm,pnames)
if (any(is.na(nparm))) {
stop("unrecognized parameter names: ",
parm[is.na(nparm)])
}
parm <- nparm
}
}
return(parm)
}
isREML <- function(x) {
if (is.null(REML <- x$modelInfo$REML)) {
## let vcov work with old (pre-REML option) stored objects
REML <- FALSE
}
return(REML)
}
## Helper function for predict.
## Assert that we can use old model (data.tmb0) as basis for
## predictions using the new data (data.tmb1):
assertIdenticalModels <- function(data.tmb1, data.tmb0, allow.new.levels=FALSE)
{
## Check terms. Only 'blockReps' and 'blockSize' are allowed to
## change.  Note that we allow e.g. spatial covariance matrices to
## change, while e.g. an unstrucured covariance must remain the
## same.
checkTerms <- function(t1, t0) {
## Defensive check:
stopifnot(identical(names(t1), names(t0)))
## *Never* allowed to differ:
testIdentical <- function(checkNm) {
unlist( Map( function(x,y)
identical(x[checkNm], y[checkNm]), t0, t1) )
}
ok <- testIdentical( c("blockNumTheta", "blockCode") )
if ( ! all(ok) ) {
msg <- c("Prediction is not possible for terms: ",
paste(names(t1)[!ok], collapse=", "), "\n",
"Probably some factor levels in 'newdata' require fitting a new model.")
stop(msg)
}
## Sometimes allowed to differ:
if ( ! allow.new.levels ) {
ok <- testIdentical( c( "blockReps", "blockSize") )
if ( ! all(ok) ) {
msg <- c("Predicting new random effect levels for terms: ",
paste(names(t1)[!ok], collapse=", "), "\n",
"Disable this warning with 'allow.new.levels=TRUE'")
## FIXME: warning or error ?
warning(msg)
}
}
}
checkTerms( data.tmb1$terms,   data.tmb0$terms )
checkTerms( data.tmb1$termszi, data.tmb0$termszi )
## Fixed effect parameters must be identical
checkModelMatrix <- function(X1, X0) {
if( !identical(colnames(X1), colnames(X0)) ) {
msg <- c("Prediction is not possible for unknown fixed effects: ",
paste( setdiff(colnames(X1), colnames(X0)), collapse=", "), "\n",
"Probably some factor levels in 'newdata' require fitting a new model.")
stop(msg)
}
}
checkModelMatrix(data.tmb1$X,   data.tmb0$X)
checkModelMatrix(data.tmb1$Xzi, data.tmb0$Xzi)
NULL
}
##' prediction
##' @param object a \code{glmmTMB} object
##' @param newdata new data for prediction
##' @param se.fit return the standard errors of the predicted values?
##' @param zitype deprecated: formerly used to specify type of zero-inflation probability. Now synonymous with \code{type}
##' @param type Denoting \eqn{mu} as the mean of the conditional distribution and
##' \code{p} as the zero-inflation probability,
##' the possible choices are:
##' \describe{
##' \item{"link"}{conditional mean on the scale of the link function,
##' or equivalently the linear predictor of the conditional model}
##' \item{"response"}{expected value; this is \eqn{mu*(1-p)} for zero-inflated models
##' and \code{mu} otherwise}
##' \item{"conditional"}{mean of the conditional response; \code{mu} for all models
##' (i.e., synonymous with \code{"response"} in the absence of zero-inflation}
##' \item{"zprob"}{the probability of a structural zero (gives an error
##' for non-zero-inflated models)}
##' \item{"zlink"}{predicted zero-inflation probability on the scale of
##' the logit link function}
##' }
##' @param na.action how to handle missing values in \code{newdata} (see \code{\link{na.action}});
##' the default (\code{na.pass}) is to predict \code{NA}
##' @param debug (logical) return the \code{TMBStruc} object that will be
##' used internally for debugging?
##' @param re.form (not yet implemented: see Details for population-level predictions) (formula, \code{NULL}, or \code{NA}) specify which random effects to condition on when predicting.
##' @param allow.new.levels allow previously unobserved levels in random-effects variables? see details.
##' @param \dots unused - for method compatibility
##' @details
##' \itemize{
##' \item To compute population-level predictions for a given grouping variable (i.e., setting all random effects for that grouping variable to zero), set the grouping variable values to \code{NA}. Finer-scale control of conditioning (e.g. allowing variation among groups in intercepts but not slopes when predicting from a random-slopes model) is not currently possible.
##' \item Prediction of new random effect levels is possible as long as the model specification (fixed effects and parameters) is kept constant.
##' However, to ensure intentional usage, a warning is triggered if \code{allow.new.levels=FALSE} (the default).
##' \item Prediction using "data-dependent bases" (variables whose scaling or transformation depends on the original data, e.g. \code{\link{poly}}, \code{\link[splines]{ns}}, or \code{\link{poly}}) should work properly; however, users are advised to check results extra-carefully when using such variables. Models with different versions of the same data-dependent basis type in different components (e.g. \code{formula= y ~ poly(x,3), dispformula= ~poly(x,2)}) will probably \emph{not} produce correct predictions.
##' }
##'
##' @examples
##' data(sleepstudy,package="lme4")
##' g0 <- glmmTMB(Reaction~Days+(Days|Subject),sleepstudy)
##' predict(g0, sleepstudy)
##' ## Predict new Subject
##' nd <- sleepstudy[1,]
##' nd$Subject <- "new"
##' predict(g0, newdata=nd, allow.new.levels=TRUE)
##' ## population-level prediction
##' nd_pop <- data.frame(Days=unique(sleepstudy$Days),
##'                      Subject=NA)
##' predict(g0, newdata=nd_pop)
##' @importFrom TMB sdreport
##' @importFrom stats optimHess model.frame na.fail na.pass napredict
##' @export
predict.glmmTMB <- function(object,newdata=NULL,
newparams = NULL,
se.fit=FALSE,
re.form = NULL, allow.new.levels=FALSE,
type = c("link", "response",
"conditional","zprob","zlink"),
zitype = NULL,
na.action = na.pass,
debug=FALSE,
...)
{
## FIXME: add re.form
if (!is.null(zitype)) {
warning("zitype is deprecated: please use type instead")
type <- zitype
}
type <- match.arg(type)
## FIXME: better test? () around re.form==~0 are *necessary*
## could steal isRE from lme4 predict.R ...
pop_pred <- (!is.null(re.form) && ((re.form==~0) ||
identical(re.form,NA)))
if (!(is.null(re.form) || pop_pred)) {
stop("re.form must equal NULL, NA, or ~0")
}
mc <- mf <- object$call
## FIXME: DRY so much
## now work on evaluating model frame
## do we want to re-do this part???
## need to 'fix' call to proper model.frame call whether or not
## we have new data, because ... (??)
m <- match(c("subset", "weights", "offset", "na.action"),
names(mf), 0L)
mf <- mf[c(1L, m)]
mf$drop.unused.levels <- TRUE
mf[[1]] <- as.name("model.frame")
## substitute *combined* data frame, in hopes of getting all of the
##  bits we need for any of the model frames ...
tt <- terms(object$modelInfo$allForm$combForm)
pv <- attr(terms(model.frame(object)),"predvars")
attr(tt,"predvars") <- fix_predvars(pv,tt)
mf$formula <- RHSForm(tt, as.form=TRUE)
## FIXME:: fix_predvars is ugly, and should be refactored.
## the best solution is probably to attach predvars information
## to formulas/terms for individual components
## {conditional, zi, disp} * {fixed, random}
## and fix things downstream, where the actual model matrices
## are constructed.
##
## There's a fairly high chance of breakage with crazy/unforeseen
## usage of data-dependent bases (e.g. polynomials or splines with
## different arguments in different parts of the model ...)
## Can we detect/warn about these?
##
if (is.null(newdata)) {
mf$data <- mc$data ## restore original data
newFr <- object$frame
} else {
mf$data <- newdata
mf$na.action <- na.action
newFr <- eval.parent(mf)
}
omi <- object$modelInfo  ## shorthand ("**o**bject$**m**odel**I**nfo")
respCol <- match(respNm <- names(omi$respCol),names(newFr))
## create *or* overwrite response column for prediction data with NA
newFr[[respNm]] <- NA
## FIXME: not yet handling population-level predictions (re.form
##  or new levels/allow.new.levels)
## append to existing model frame
augFr <- rbind(object$fr,newFr)
## Pointers into 'new rows' of augmented data frame.
w <- nrow(object$fr) + seq_len(nrow(newFr))
## Variety of possible binomial inputs are taken care of by
## 'mkTMBStruc' further down.
yobs <- augFr[[names(omi$respCol)]]
## match type arg with internal name
## FIXME: warn if "link"
ziPredNm <- switch(type,
response   = "corrected",
link       =,
conditional= "uncorrected",
zlink      = ,
zprob      = "prob",
stop("unknown type ",type))
ziPredCode <- .valid_zipredictcode[ziPredNm]
## need eval.parent() because we will do eval(mf) down below ...
TMBStruc <-
## FIXME: make first arg of mkTMBStruc into a formula list
## with() interfering with eval.parent() ?
eval.parent(mkTMBStruc(RHSForm(omi$allForm$formula,as.form=TRUE),
omi$allForm$ziformula,
omi$allForm$dispformula,
omi$allForm$combForm,
mf,
fr=augFr,
yobs=yobs,
respCol=respCol,
weights=model.weights(augFr),
contrasts=omi$contrasts,
family=omi$family,
ziPredictCode=ziPredNm,
doPredict=as.integer(se.fit),
whichPredict=w,
REML=omi$REML,
map=omi$map))
## short-circuit
if(debug) return(TMBStruc)
## Check that the model specification is unchanged:
assertIdenticalModels(TMBStruc$data.tmb,
object$obj$env$data, allow.new.levels)
## Check that the necessary predictor variables are finite (not NA nor NaN)
if(se.fit) {
with(TMBStruc$data.tmb, if(any(!is.finite(X)) |
any(!is.finite(Z@x)) |
any(!is.finite(Xzi)) |
any(!is.finite(Zzi@x)) |
any(!is.finite(Xd))
) stop("Some variables in newdata needed for predictions contain NAs or NaNs.
This is currently incompatible with se.fit=TRUE."))
## FIXME: what if newparams only has a subset of components?
oldPar <- object$fit$par
if (!is.null(newparams)) oldPar <- newparams
if (pop_pred) {
TMBStruc <- within(TMBStruc, {
parameters$b[] <- 0
mapArg$b <- factor(rep(NA,length(parameters$b)))
})
}
}
newObj <- with(TMBStruc,
MakeADFun(data.tmb,
parameters,
map = mapArg,
random = randomArg,
profile = NULL, # TODO: Optionally "beta"
silent = TRUE,
DLL = "glmmTMB"))
newObj$fn(oldPar)  ## call once to update internal structures
lp <- newObj$env$last.par
na.act <- attr(model.frame(object),"na.action")
do.napred <- missing(newdata) && !is.null(na.act)
if (!se.fit) {
pred <- newObj$report(lp)$mu_predict
} else {
H <- with(object,optimHess(oldPar,obj$fn,obj$gr))
## FIXME: Eventually add 'getReportCovariance=FALSE' to this sdreport
##        call to fix memory issue (requires recent TMB version)
## Fixed! (but do we want a flag to get it ? ...)
sdr <- sdreport(newObj,oldPar,hessian.fixed=H,getReportCovariance=FALSE)
sdrsum <- summary(sdr, "report") ## TMB:::summary.sdreport(sdr, "report")
pred <- sdrsum[,"Estimate"]
se <- sdrsum[,"Std. Error"]
}
if (do.napred) {
pred <- napredict(na.act,pred)
if (se.fit) se <- napredict(na.act,se)
}
if (type %in% c("zlink","link")) {
ff <- object$modelInfo$family
if (!(type=="link" && ff$link=="identity")) {
if (type=="zlink") {
ff <- make.link("logit")
}
pred <- ff$linkfun(pred)
if (se.fit) se <- se/ff$mu.eta(pred) ## do this after transforming pred!
} ## if not identity link
} ## if link or zlink
if (!se.fit) return(pred) else return(list(fit=pred,se.fit=se))
}
x = predict(g0, re.form = NA, newdata=nd_pop)
g0 <- glmmTMB(Reaction~Days+(Days|Subject),sleepstudy)
predict(g0, sleepstudy)
## Predict new Subject
nd <- sleepstudy[1,]
glmmTMB::predict(g0, sleepstudy)
?predict
stats::predict(g0, sleepstudy)
stats::predict(g0, sleepstudy)
View(lm_eqn)
library(tidyverse)
library(glmmTMB)
library(ggeffects)
library(DHARMa)
library(MuMIn)
library(cowplot)
library(AICcmodavg)
library(latexpdf)
library(MATA)
predict(g0, sleepstudy)
## Predict new Subject
nd <- sleepstudy[1,]
nd$Subject <- "new"
predict(g0, newdata=nd, allow.new.levels=TRUE)
## population-level prediction
nd_pop <- data.frame(Days=unique(sleepstudy$Days),
Subject=NA)
x = predict(g0, re.form = NA, newdata=nd_pop)
x = predict(g0, newdata=nd_pop)
x = predict(g0, newdata=nd_pop, se.fit = TRUE)
model = sapply(lepconfset1, predict, newdata = newdata)
leppredict1 = data.frame(
model = sapply(lepconfset1, predict, newdata = newdata),
averagedfull = predict(lep4, newdata = newdata, allow.new.levels = TRUE))
View(newdata)
x = predict(lep4, se.fit = TRUE)
leppredict1 = data.frame(
model = sapply(lepconfset1, predict),
averagedfull = predict(lep4, allow.new.levels = TRUE))
View(leppredict1)
leppredict1 = data.frame(
model = sapply(lepconfset1, predict),
averagedfull = predict(lep4, allow.new.levels = TRUE, se.fit = TRUE))
leppredict1 = data.frame(
model = sapply(lepconfset1, predict),
averagedfull = predict(lep4, allow.new.levels = TRUE, full = TRUE))
leppredict1 = data.frame(
model = sapply(lepconfset1, predict),
averagedfull = predict(lep4, allow.new.levels = TRUE, full = TRUE, type = 'response'))
leppredict1 = data.frame(
model = sapply(lepconfset1, predict),
averagedfull = predict(lep4, allow.new.levels = TRUE, full = TRUE, type = 'response', newdata = newdata))
unique(leppredict1$averagedfull)
leppredict1 = data.frame(
model = sapply(lepconfset1, predict),
newdata$collection = NA,
newdata$collection = NA
leppredict1 = data.frame(
model = sapply(lepconfset1, predict),
averagedfull = predict(lep4, allow.new.levels = TRUE, full = TRUE, type = 'response', newdata = newdata))
newcross = unique(mainlice[,c('site.region', 'year')])
View(newcross)
DI = as.vector(rep('D', 12)); JS = as.vector(rep('J', 12))
f = as.vector(rep('2015', 3)); si = as.vector(rep('2016', 3)); sv = as.vector(rep('2017', 3)); e = as.vector(rep('2018', 3))
year = as.vector(cbind(f, si, sv, e)); year = as.vector(replicate(2, year))
CU = 'CU'; PI = 'PI'; SO = 'SO'
spp = as.vector(rbind(CU, PI, SO)); spp = as.vector(replicate(8, spp))
newdata <- matrix(nrow = 24, ncol = 4)
newdata[c(1:12), 1] = DI; newdata[c(13:24), 1] = JS
newdata[c(1:24), 2] = year
newdata[c(1:24), 3] = spp
newdata = data.frame(newdata)
newdata = newdata %>%
rename(site.region = `X1`, year = `X2`, spp = `X3`, collection = `X4`)
newdata$collection = NA
leppredict1 = data.frame(
model = sapply(lepconfset1, predict),
averagedfull = predict(lep4, allow.new.levels = TRUE, full = TRUE, type = 'response', newdata = newdata))
leppredict1 = data.frame(
model = sapply(lepconfset1, predict, newdata = newdata),
averagedfull = predict(lep4, allow.new.levels = TRUE, full = TRUE, type = 'response', newdata = newdata))
View(leppredict1)
leppredict1 = data.frame(
model = sapply(lepconfset1, predict, newdata = newdata),
averagedfull = predict(lep4, allow.new.levels = TRUE, full = TRUE, type = 'response', newdata = newdata, se.fit = TRUE))
leppredict1$low = leppredict1$averagedfull.fit - (1.96*leppredict1$averagedfull.se.fit)
View(leppredict1)
View(lepallpred)
leppredict1 = data.frame(
model = sapply(lepconfset1, predict, newdata = newdata),
averagedfull = predict(lep4, allow.new.levels = TRUE, full = TRUE, newdata = newdata, se.fit = TRUE))
leppredict1 = data.frame(
model = sapply(lepconfset1, predict, newdata = newdata),
averagedfull = predict(lep4, type = 'response', newdata = newdata, se.fit = TRUE))
leppredict1$low = leppredict1$averagedfull.fit - (1.96*leppredict1$averagedfull.se.fit)
View(lepallpred)
leppredict1$mine = lepallpred$avg
leppredict1$mine.low = leppredict1$mine - (1.96*leppredict1$averagedfull.se.fit)
